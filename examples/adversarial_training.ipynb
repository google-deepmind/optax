{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAM1nM3wQ4Nt"
      },
      "source": [
        "Copyright 2023 Google LLC\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "you may not use this file except in compliance with the License.\n",
        "You may obtain a copy of the License at\n",
        "\n",
        "     https://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software\n",
        "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "See the License for the specific language governing permissions and\n",
        "limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cib2jXJDQ4Nz"
      },
      "source": [
        "# Adversarial training\n",
        "\n",
        "\n",
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/google-deepmind/optax/blob/main/examples/adversarial_training.ipynb)\n",
        "\n",
        "\n",
        "The following code trains a convolutional neural network (CNN) to be robust\n",
        "with respect to the projected gradient descent (PGD) method.\n",
        "\n",
        "The Projected Gradient Descent Method (PGD) is a simple yet effective method to\n",
        "generate adversarial images. At each iteration, it adds a small perturbation\n",
        "in the direction of the sign of the gradient with respect to the input followed\n",
        "by a projection onto the infinity ball. The gradient sign ensures this\n",
        "perturbation locally maximizes the objective, while the projection ensures this\n",
        "perturbation stays on the boundary of the infinity ball.\n",
        "\n",
        "## References\n",
        "\n",
        "  Goodfellow, Ian J., Jonathon Shlens, and Christian Szegedy. \"Explaining\n",
        "  and harnessing adversarial examples.\", https://arxiv.org/abs/1412.6572\n",
        "\n",
        "  Madry, Aleksander, et al. \"Towards deep learning models resistant to\n",
        "  adversarial attacks.\", https://arxiv.org/abs/1706.06083"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "diO66z2ZQ4N3",
        "outputId": "e3f2cd69-7dba-452b-82ef-7539d4ae5493"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "\n",
        "import jax\n",
        "from jax import numpy as jnp\n",
        "from flax import linen as nn\n",
        "\n",
        "import optax\n",
        "from optax.losses import softmax_cross_entropy_with_integer_labels\n",
        "from optax.tree_utils import tree_l2_norm\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "plt.rcParams.update({'font.size': 22})\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "# Hide any GPUs from TensorFlow. Otherwise TF might reserve memory and make\n",
        "# it unavailable to JAX.\n",
        "tf.config.experimental.set_visible_devices([], \"GPU\")\n",
        "\n",
        "# Show on which platform JAX is running.\n",
        "print(\"JAX running on\", jax.devices()[0].platform.upper())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sWqYXjZFpUXe"
      },
      "outputs": [],
      "source": [
        "# @markdown Total number of epochs to train for:\n",
        "EPOCHS = 10  # @param{type:\"integer\"}\n",
        "# @markdown Number of samples for each batch in the training set:\n",
        "TRAIN_BATCH_SIZE = 128  # @param{type:\"integer\"}\n",
        "# @markdown Number of samples for each batch in the test set:\n",
        "TEST_BATCH_SIZE = 128  # @param{type:\"integer\"}\n",
        "# @markdown Learning rate for the optimizer:\n",
        "LEARNING_RATE = 0.001  # @param{type:\"number\"}\n",
        "# @markdown The dataset to use.\n",
        "DATASET = \"mnist\"  # @param{type:\"string\"}\n",
        "# @markdown The amount of L2 regularization to use:\n",
        "L2_REG = 0.0001  # @param{type:\"number\"}\n",
        "# @markdown Adversarial perturbations lie within the infinity-ball of radius epsilon.\n",
        "EPSILON = 0.01 # @param{type:\"number\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kwr2gSOZQ4N7"
      },
      "outputs": [],
      "source": [
        "class CNN(nn.Module):\n",
        "  \"\"\"A simple CNN model.\"\"\"\n",
        "  num_classes: int\n",
        "\n",
        "  @nn.compact\n",
        "  def __call__(self, x):\n",
        "    x = nn.Conv(features=32, kernel_size=(3, 3))(x)\n",
        "    x = nn.relu(x)\n",
        "    x = nn.avg_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
        "    x = nn.Conv(features=64, kernel_size=(3, 3))(x)\n",
        "    x = nn.relu(x)\n",
        "    x = nn.avg_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
        "    x = x.reshape((x.shape[0], -1))  # flatten\n",
        "    x = nn.Dense(features=256)(x)\n",
        "    x = nn.relu(x)\n",
        "    x = nn.Dense(features=self.num_classes)(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NUBxQ4c5LPwp"
      },
      "outputs": [],
      "source": [
        "(train_loader, test_loader), mnist_info = tfds.load(\"mnist\", split=[\"train\", \"test\"], as_supervised=True, with_info=True)\n",
        "\n",
        "train_loader_batched = train_loader.shuffle(10 * TRAIN_BATCH_SIZE, seed=0).batch(TRAIN_BATCH_SIZE, drop_remainder=True)\n",
        "test_loader_batched = test_loader.batch(TEST_BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "input_shape = (1,) + mnist_info.features[\"image\"].shape\n",
        "num_classes = mnist_info.features[\"label\"].num_classes\n",
        "iter_per_epoch_train = mnist_info.splits['train'].num_examples // TRAIN_BATCH_SIZE\n",
        "iter_per_epoch_test = mnist_info.splits['test'].num_examples // TEST_BATCH_SIZE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "trBo7PpcQ4N8"
      },
      "outputs": [],
      "source": [
        "net = CNN(num_classes)\n",
        "\n",
        "@jax.jit\n",
        "def accuracy(params, data):\n",
        "  inputs, labels = data\n",
        "  logits = net.apply({\"params\": params}, inputs)\n",
        "  return jnp.mean(jnp.argmax(logits, axis=-1) == labels)\n",
        "\n",
        "\n",
        "@jax.jit\n",
        "def loss_fun(params, l2reg, data):\n",
        "  \"\"\"Compute the loss of the network.\"\"\"\n",
        "  inputs, labels = data\n",
        "  x = inputs.astype(jnp.float32)\n",
        "  logits = net.apply({\"params\": params}, x)\n",
        "  sqnorm = tree_l2_norm(params, squared=True)\n",
        "  loss_value = jnp.mean(softmax_cross_entropy_with_integer_labels(logits, labels))\n",
        "  return loss_value + 0.5 * l2reg * sqnorm\n",
        "\n",
        "@jax.jit\n",
        "def pgd_attack(image, label, params, epsilon=0.1, maxiter=10):\n",
        "  \"\"\"PGD attack on the L-infinity ball with radius epsilon.\n",
        "\n",
        "  Args:\n",
        "    image: array-like, input data for the CNN\n",
        "    label: integer, class label corresponding to image\n",
        "    params: tree, parameters of the model to attack\n",
        "    epsilon: float, radius of the L-infinity ball.\n",
        "    maxiter: int, number of iterations of this algorithm.\n",
        "\n",
        "  Returns:\n",
        "    perturbed_image: Adversarial image on the boundary of the L-infinity ball\n",
        "      of radius epsilon and centered at image.\n",
        "\n",
        "  Notes:\n",
        "    PGD attack is described in (Madry et al. 2017),\n",
        "    https://arxiv.org/pdf/1706.06083.pdf\n",
        "  \"\"\"\n",
        "  image_perturbation = jnp.zeros_like(image)\n",
        "  def adversarial_loss(perturbation):\n",
        "    return loss_fun(params, 0, (image + perturbation, label))\n",
        "\n",
        "  grad_adversarial = jax.grad(adversarial_loss)\n",
        "  for _ in range(maxiter):\n",
        "    # compute gradient of the loss wrt to the image\n",
        "    sign_grad = jnp.sign(grad_adversarial(image_perturbation))\n",
        "\n",
        "    # heuristic step-size 2 eps / maxiter\n",
        "    image_perturbation += (2 * epsilon / maxiter) * sign_grad\n",
        "    # projection step onto the L-infinity ball centered at image\n",
        "    image_perturbation = jnp.clip(image_perturbation, - epsilon, epsilon)\n",
        "\n",
        "  # clip the image to ensure pixels are between 0 and 1\n",
        "  return jnp.clip(image + image_perturbation, 0, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QgQcIgg2Z2XB"
      },
      "outputs": [],
      "source": [
        "def dataset_stats(params, data_loader, iter_per_epoch):\n",
        "  \"\"\"Computes accuracy on clean and adversarial images.\"\"\"\n",
        "  adversarial_accuracy = 0.\n",
        "  clean_accuracy = 0.\n",
        "  for batch in data_loader.as_numpy_iterator():\n",
        "    images, labels = batch\n",
        "    images = images.astype(jnp.float32) / 255\n",
        "    clean_accuracy += jnp.mean(accuracy(params, (images, labels))) / iter_per_epoch\n",
        "    adversarial_images = pgd_attack(images, labels, params, epsilon=EPSILON)\n",
        "    adversarial_accuracy += jnp.mean(accuracy(params, (adversarial_images, labels))) / iter_per_epoch\n",
        "  return {\"adversarial accuracy\": adversarial_accuracy, \"accuracy\": clean_accuracy}\n",
        "\n",
        "@jax.jit\n",
        "def train_step(params, opt_state, batch):\n",
        "  images, labels = batch\n",
        "  # convert images to float as attack requires to take gradients wrt to them\n",
        "  images = images.astype(jnp.float32) / 255\n",
        "  adversarial_images_train = pgd_attack(images, labels, params, epsilon=EPSILON)\n",
        "  # train on adversarial images\n",
        "  loss_grad_fun = jax.grad(loss_fun)\n",
        "  grads = loss_grad_fun(params, L2_REG, (adversarial_images_train, labels))\n",
        "  updates, opt_state = optimizer.update(grads, opt_state)\n",
        "  params = optax.apply_updates(params, updates)\n",
        "  return params, opt_state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwt6HuxhCd1a",
        "outputId": "982662b7-a338-459c-d1fd-bdad657efa8c"
      },
      "outputs": [],
      "source": [
        "# Initialize parameters.\n",
        "key = jax.random.PRNGKey(0)\n",
        "params = net.init(key, jnp.zeros(input_shape))[\"params\"]\n",
        "\n",
        "# Initialize the optimizer.\n",
        "optimizer = optax.adam(LEARNING_RATE)\n",
        "opt_state = optimizer.init(params)\n",
        "\n",
        "start = datetime.datetime.now().replace(microsecond=0)\n",
        "\n",
        "accuracy_train = []\n",
        "accuracy_test = []\n",
        "adversarial_accuracy_train = []\n",
        "adversarial_accuracy_test = []\n",
        "for epoch in range(EPOCHS):\n",
        "  for batch in train_loader_batched.as_numpy_iterator():\n",
        "    params, opt_state = train_step(params, opt_state, batch)\n",
        "\n",
        "  # compute train set accuracy, both on clean and adversarial images\n",
        "  train_stats = dataset_stats(params, train_loader_batched, iter_per_epoch_train)\n",
        "  accuracy_train.append(train_stats[\"accuracy\"])\n",
        "  adversarial_accuracy_train.append(train_stats[\"adversarial accuracy\"])\n",
        "\n",
        "  # compute test set accuracy, both on clean and adversarial images\n",
        "  test_stats = dataset_stats(params, test_loader_batched, iter_per_epoch_test)\n",
        "  accuracy_test.append(test_stats[\"accuracy\"])\n",
        "  adversarial_accuracy_test.append(test_stats[\"adversarial accuracy\"])\n",
        "\n",
        "  time_elapsed = (datetime.datetime.now().replace(microsecond=0) - start)\n",
        "  print(f\"Epoch {epoch} out of {EPOCHS}\")\n",
        "  print(f\"Accuracy on train set: {accuracy_train[-1]:.3f}\")\n",
        "  print(f\"Accuracy on test set: {accuracy_test[-1]:.3f}\")\n",
        "  print(f\"Adversarial accuracy on train set: {adversarial_accuracy_train[-1]:.3f}\")\n",
        "  print(f\"Adversarial accuracy on test set: {adversarial_accuracy_test[-1]:.3f}\")\n",
        "  print(f\"Time elapsed: {time_elapsed}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 673
        },
        "id": "vQnv1S84Q4N-",
        "outputId": "f0b39abe-04b4-4a5e-be0d-e239dad4de31"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(16, 6))\n",
        "\n",
        "plt.suptitle(\"Adversarial training on \" + f\"{DATASET}\".upper())\n",
        "axes[0].plot(accuracy_train, lw=3, label=\"train set.\" , marker='<', markersize=10)\n",
        "axes[0].plot(accuracy_test, lw=3, label=\"test set.\", marker='d', markersize=10)\n",
        "axes[0].grid()\n",
        "axes[0].set_ylabel('accuracy on clean images')\n",
        "\n",
        "axes[1].plot(\n",
        "    adversarial_accuracy_train,\n",
        "    lw=3,\n",
        "    label=\"adversarial accuracy on train set.\", marker='^', markersize=10)\n",
        "axes[1].plot(\n",
        "    adversarial_accuracy_test,\n",
        "    lw=3,\n",
        "    label=\"adversarial accuracy on test set.\", marker='>', markersize=10)\n",
        "axes[1].grid()\n",
        "axes[0].legend(frameon=False, ncol=2, loc='upper center', bbox_to_anchor=(0.8, -0.1))\n",
        "axes[0].set_xlabel('epochs')\n",
        "axes[1].set_ylabel('accuracy on adversarial images')\n",
        "plt.subplots_adjust( wspace=0.5 )\n",
        "\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAPfMtFKQ4N-"
      },
      "source": [
        "Find a test set image that is correctly classified but not its adversarial perturbation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5o-Qf1qEQ4N_"
      },
      "outputs": [],
      "source": [
        "def find_adversarial_imgs():\n",
        "  for batch in test_loader_batched.as_numpy_iterator():\n",
        "    images, labels = batch\n",
        "    images = images.astype(jnp.float32) / 255\n",
        "    logits = net.apply({\"params\": params}, images)\n",
        "    labels_clean = jnp.argmax(logits, axis=-1)\n",
        "\n",
        "    adversarial_images = pgd_attack(\n",
        "      images, labels, params, epsilon=EPSILON)\n",
        "    labels_adversarial = jnp.argmax(net.apply({\"params\": params}, adversarial_images), axis=-1)\n",
        "    idx_misclassified = jnp.where(labels_clean != labels_adversarial)[0]\n",
        "    if len(idx_misclassified) == 0:\n",
        "      continue\n",
        "    else:\n",
        "      for i in idx_misclassified:\n",
        "        img_clean = images[i]\n",
        "        prediction_clean = labels_clean[i]\n",
        "        if prediction_clean != labels[i]:\n",
        "          # the clean image predicts the wrong label, skip\n",
        "          continue\n",
        "        img_adversarial = adversarial_images[i]\n",
        "        prediction_adversarial = labels_adversarial[i]\n",
        "        # we found our image\n",
        "        return img_clean, prediction_clean, img_adversarial, prediction_adversarial\n",
        "\n",
        "  raise ValueError(\"No mismatch between clean and adversarial prediction found\")\n",
        "\n",
        "img_clean, prediction_clean, img_adversarial, prediction_adversarial = \\\n",
        "  find_adversarial_imgs()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 651
        },
        "id": "aF2-kSuQQ4N_",
        "outputId": "45b53065-0f10-487d-ffe5-3e13e66110e2"
      },
      "outputs": [],
      "source": [
        "_, axes = plt.subplots(nrows=1, ncols=3, figsize=(6*3, 6))\n",
        "\n",
        "axes[0].set_title('Clean image \\n Prediction %s' % int(prediction_clean))\n",
        "axes[0].imshow(img_clean, cmap=plt.cm.get_cmap('Greys'), vmax=1, vmin=0)\n",
        "axes[1].set_title('Adversarial image \\n Prediction %s' % prediction_adversarial)\n",
        "axes[1].imshow(img_adversarial, cmap=plt.cm.get_cmap('Greys'), vmax=1, vmin=0)\n",
        "axes[2].set_title(r'|Adversarial - clean| $\\times$ %.0f' % (1/EPSILON))\n",
        "axes[2].imshow(jnp.abs(img_clean - img_adversarial) / EPSILON, cmap=plt.cm.get_cmap('Greys'), vmax=1, vmin=0)\n",
        "for i in range(3):\n",
        "    axes[i].set_xticks(())\n",
        "    axes[i].set_yticks(())\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pG7U7jzxQ4OA"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "jupytext": {
      "formats": "ipynb,md:myst"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "5c7b89af1651d0b8571dde13640ecdccf7d5a6204171d6ab33e7c296e100e08a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
